---
# Determines which item appears first on the schedule (lowest number (0) appears first)
sequence_id: 1

# Speaker name
speaker: Laura Weidinger 

# Title of the event
title: Sociotechnical Safety Evaluation of AI systems 

# Time of the event
time: 0910 - 0940

webpage:

abstract: Generative AI enables new use cases and modes of human-AI-interaction. These create ethical, social and safety risks which must be assessed in order to be managed or mitigated. However, current approaches to AI safety evaluation may miss relevant hazards due to not taking into account all relevant context, such as who uses the system and to what end. In this talk, I introduce a sociotechnical framework to AI safety evaluation that aims to capture relevant complexity, providing a holistic approach to AI safety evaluation. I canvass the current state of AI safety evaluation and point out key gaps. To close these gaps, I discuss possibilities for the field to expand beyond current evaluation methods and point out open challenges such as accuracy/ cost trade-offs, and representativeness and consent in the context of user studies and simulations. I close by highlighting ways toward implementing a sociotechnical approach to safety evaluation.


---
